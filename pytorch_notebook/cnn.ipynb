{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.Compose(): This function is used to compose multiple transformations into a single transformation.\n",
    "# transforms.ToTensor(): This transformation converts a PIL image to a PyTorch tensor.\n",
    "# transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)): This transformation normalizes the pixel values of the image to have a mean of 0.5 and a standard deviation of 0.5 for each color channel (R, G, B).\n",
    "# Purpose:               r   g     b       r   g     b\n",
    "# The purpose of this transformation is to prepare image data for training a neural network. By normalizing the pixel values, the network can learn more efficiently and accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line of code reverses the normalization process that was applied to the image earlier. When normalizing an image, \n",
    "# the pixel values are usually scaled to a range between -1 and 1 or 0 and 1. This line of code scales the pixel values back \n",
    "# to their original range.\n",
    "# This line of code converts the PyTorch tensor img to a NumPy array npimg.\n",
    "# In PyTorch, images are typically represented as tensors with shape (channels, height, width). However, Matplotlib's \n",
    "# imshow function expects images to have shape (height, width, channels). This line of code swaps the dimensions to match\n",
    "# Matplotlib's expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7020, -0.6863, -0.5922,  ..., -0.6706, -0.7098, -0.7569],\n",
       "          [-0.4275, -0.3020, -0.4118,  ..., -0.6471, -0.7255, -0.7725],\n",
       "          [-0.5608, -0.3020, -0.1137,  ..., -0.6157, -0.6078, -0.7569],\n",
       "          ...,\n",
       "          [-0.8353, -0.7961, -0.7176,  ..., -0.7490, -0.7882, -0.7333],\n",
       "          [-0.7961, -0.7804, -0.7255,  ..., -0.6314, -0.7255, -0.7098],\n",
       "          [-0.7176, -0.7882, -0.7647,  ..., -0.6863, -0.6863, -0.7098]],\n",
       "\n",
       "         [[-0.6706, -0.6627, -0.6078,  ..., -0.7020, -0.7412, -0.7882],\n",
       "          [-0.3961, -0.3020, -0.4431,  ..., -0.6784, -0.7490, -0.7961],\n",
       "          [-0.5529, -0.3255, -0.1529,  ..., -0.6392, -0.6235, -0.7804],\n",
       "          ...,\n",
       "          [-0.8510, -0.8118, -0.7333,  ..., -0.7725, -0.8118, -0.7569],\n",
       "          [-0.8118, -0.7961, -0.7412,  ..., -0.6549, -0.7490, -0.7333],\n",
       "          [-0.7333, -0.8039, -0.7804,  ..., -0.7098, -0.7098, -0.7333]],\n",
       "\n",
       "         [[-0.4353, -0.4275, -0.3412,  ..., -0.4353, -0.4824, -0.5294],\n",
       "          [-0.1765, -0.0431, -0.1451,  ..., -0.4039, -0.5137, -0.5529],\n",
       "          [-0.3333, -0.0667,  0.1373,  ..., -0.4039, -0.4275, -0.5608],\n",
       "          ...,\n",
       "          [-0.6549, -0.6235, -0.5451,  ..., -0.5451, -0.5843, -0.5294],\n",
       "          [-0.6235, -0.6157, -0.5529,  ..., -0.4275, -0.5216, -0.5059],\n",
       "          [-0.5373, -0.6157, -0.5922,  ..., -0.4902, -0.4824, -0.5137]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5922,  0.5451,  0.5216,  ...,  0.4902,  0.5059,  0.5451],\n",
       "          [ 0.6078,  0.5608,  0.5373,  ...,  0.5059,  0.5137,  0.5608],\n",
       "          [ 0.6078,  0.5529,  0.5294,  ...,  0.4824,  0.4980,  0.5529],\n",
       "          ...,\n",
       "          [-0.6078, -0.5451, -0.4902,  ..., -0.5843, -0.5843, -0.5529],\n",
       "          [-0.7020, -0.6627, -0.5765,  ..., -0.5765, -0.5529, -0.5294],\n",
       "          [-0.6941, -0.6706, -0.6471,  ..., -0.6314, -0.5529, -0.5059]],\n",
       "\n",
       "         [[ 0.6941,  0.6471,  0.6157,  ...,  0.5922,  0.6000,  0.6392],\n",
       "          [ 0.6941,  0.6471,  0.6235,  ...,  0.5922,  0.6000,  0.6471],\n",
       "          [ 0.6863,  0.6314,  0.6078,  ...,  0.5608,  0.5765,  0.6235],\n",
       "          ...,\n",
       "          [-0.2157, -0.1922, -0.1765,  ..., -0.3490, -0.3569, -0.3255],\n",
       "          [-0.3098, -0.3098, -0.2549,  ..., -0.3412, -0.3176, -0.2941],\n",
       "          [-0.3098, -0.3255, -0.3255,  ..., -0.3961, -0.3176, -0.2706]],\n",
       "\n",
       "         [[ 0.7647,  0.7176,  0.6863,  ...,  0.6627,  0.6706,  0.7176],\n",
       "          [ 0.7725,  0.7176,  0.7020,  ...,  0.6627,  0.6784,  0.7255],\n",
       "          [ 0.7569,  0.7020,  0.6784,  ...,  0.6314,  0.6471,  0.6941],\n",
       "          ...,\n",
       "          [ 0.0588,  0.0588,  0.0588,  ..., -0.1529, -0.1686, -0.1373],\n",
       "          [-0.0275, -0.0510, -0.0196,  ..., -0.1373, -0.1137, -0.0824],\n",
       "          [-0.0353, -0.0667, -0.0902,  ..., -0.1922, -0.1137, -0.0588]]],\n",
       "\n",
       "\n",
       "        [[[-0.3176, -0.3804, -0.3412,  ...,  0.0980,  0.1216,  0.0980],\n",
       "          [-0.3725, -0.3804, -0.3255,  ...,  0.0510,  0.0275,  0.0745],\n",
       "          [-0.4353, -0.3725, -0.2941,  ..., -0.0824, -0.0980,  0.0196],\n",
       "          ...,\n",
       "          [-0.3569, -0.3255, -0.3255,  ..., -0.2549, -0.2941, -0.2941],\n",
       "          [-0.3176, -0.3490, -0.3098,  ..., -0.2706, -0.3098, -0.2863],\n",
       "          [-0.3098, -0.3333, -0.3098,  ..., -0.2941, -0.2941, -0.2941]],\n",
       "\n",
       "         [[-0.4824, -0.5216, -0.4745,  ...,  0.1059,  0.1294,  0.1059],\n",
       "          [-0.5451, -0.5294, -0.4667,  ...,  0.0510,  0.0275,  0.0824],\n",
       "          [-0.6078, -0.5216, -0.4275,  ..., -0.0902, -0.0980,  0.0275],\n",
       "          ...,\n",
       "          [-0.5059, -0.4745, -0.4118,  ..., -0.2549, -0.2863, -0.2863],\n",
       "          [-0.4667, -0.4980, -0.4039,  ..., -0.2706, -0.3098, -0.2863],\n",
       "          [-0.4667, -0.4824, -0.4039,  ..., -0.2941, -0.2941, -0.2941]],\n",
       "\n",
       "         [[-0.9059, -0.9137, -0.8667,  ...,  0.0431,  0.0667,  0.0431],\n",
       "          [-0.9373, -0.8980, -0.8275,  ...,  0.0275, -0.0118,  0.0275],\n",
       "          [-0.9765, -0.8824, -0.7725,  ..., -0.0824, -0.1216, -0.0196],\n",
       "          ...,\n",
       "          [-0.9451, -0.9137, -0.8902,  ..., -0.2706, -0.3176, -0.3176],\n",
       "          [-0.9216, -0.9373, -0.8902,  ..., -0.2863, -0.3255, -0.3020],\n",
       "          [-0.9059, -0.9137, -0.8745,  ..., -0.3098, -0.3020, -0.2941]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4118,  0.4431,  0.4196,  ...,  0.2235,  0.2157,  0.1922],\n",
       "          [ 0.3647,  0.3333,  0.3569,  ...,  0.1922,  0.2941,  0.3176],\n",
       "          [ 0.2706,  0.3020,  0.3647,  ...,  0.2392,  0.3333,  0.3098],\n",
       "          ...,\n",
       "          [-0.4667, -0.5608, -0.5765,  ..., -0.0431, -0.0275, -0.1294],\n",
       "          [-0.4980, -0.6078, -0.5922,  ..., -0.1294, -0.1294, -0.1608],\n",
       "          [-0.5373, -0.6314, -0.6157,  ..., -0.1608, -0.1137, -0.1294]],\n",
       "\n",
       "         [[ 0.3569,  0.3804,  0.3412,  ...,  0.1294,  0.1294,  0.0980],\n",
       "          [ 0.3020,  0.2706,  0.2627,  ...,  0.0667,  0.1686,  0.2000],\n",
       "          [ 0.2000,  0.2157,  0.2471,  ...,  0.0902,  0.1686,  0.1686],\n",
       "          ...,\n",
       "          [-0.5529, -0.6157, -0.6392,  ..., -0.1451, -0.1294, -0.2000],\n",
       "          [-0.5765, -0.6471, -0.6235,  ..., -0.2235, -0.2000, -0.2157],\n",
       "          [-0.6157, -0.6706, -0.6549,  ..., -0.2471, -0.2000, -0.2000]],\n",
       "\n",
       "         [[ 0.1529,  0.1686,  0.1373,  ..., -0.0588, -0.0824, -0.1373],\n",
       "          [ 0.0980,  0.0667,  0.0667,  ..., -0.0980, -0.0196, -0.0275],\n",
       "          [ 0.0039,  0.0118,  0.0510,  ..., -0.0588, -0.0196, -0.0353],\n",
       "          ...,\n",
       "          [-0.6235, -0.6863, -0.7020,  ..., -0.2784, -0.2627, -0.3255],\n",
       "          [-0.6471, -0.7098, -0.6784,  ..., -0.3490, -0.3176, -0.3333],\n",
       "          [-0.6627, -0.7255, -0.7098,  ..., -0.3725, -0.3098, -0.3098]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 8, 6, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images: A tensor of images with shape (B, C, H, W), where:\n",
    "# B is the batch size (number of images).\n",
    "# C is the number of color channels (e.g., 3 for RGB).\n",
    "# H is the height of each image.\n",
    "# W is the width of each image.\n",
    "# Returns:\n",
    "# A tensor with shape (C, H_grid, W_grid), where:\n",
    "# H_grid is the height of the grid.\n",
    "# W_grid is the width of the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code defines a series of layers for a Convolutional Neural Network (CNN) in PyTorch.\n",
    "\n",
    "# self.conv1 = nn.Conv2d(3, 6, 5):\n",
    "\n",
    "# This line defines the first convolutional layer.\n",
    "# 3: The number of input channels (e.g., 3 for RGB images).\n",
    "# 6: The number of output channels (filters).\n",
    "# 5: The size of the convolutional kernel (filter size).\n",
    "# self.pool = nn.MaxPool2d(2, 2):\n",
    "\n",
    "# This line defines a max-pooling layer.\n",
    "# 2, 2: The size of the pooling window is 2x2.  # stride 2\n",
    "# self.conv2 = nn.Conv2d(6, 16, 5):\n",
    "\n",
    "# This defines the second convolutional layer.\n",
    "# 6: The number of input channels (from the previous convolutional layer).\n",
    "# 16: The number of output channels.\n",
    "# 5: The size of the convolutional kernel.\n",
    "# self.fc1 = nn.Linear(16 * 5 * 5, 120):\n",
    "\n",
    "# This defines the first fully connected (linear) layer.\n",
    "# 16 * 5 * 5: The input size of this layer. This is calculated based on the output of the previous convolutional layers and pooling.\n",
    "# 120: The number of neurons in this layer.\n",
    "# self.fc2 = nn.Linear(120, 84):\n",
    "\n",
    "# This defines the second fully connected layer.\n",
    "# 120: The input size from the previous fully connected layer.\n",
    "# 84: The number of neurons in this layer.\n",
    "# self.fc3 = nn.Linear(84, 10):\n",
    "\n",
    "# This defines the final fully connected layer.\n",
    "# 84: The input size from the previous fully connected layer.\n",
    "# 10: The number of output neurons. This likely corresponds to the number of classes in a classification problem (e.g., 10 classes for classifying images of digits 0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # This is the constructor method that initializes the ConvNet class. The super function calls the constructor of the parent class (nn.Module).\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        # fc1, fc2, and fc3: Fully connected (dense) layers with the specified input and output dimensions.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = self.pool(F.relu(self.conv1(x)))\n",
    "\n",
    "# self.conv1(x): This applies the first convolutional layer (self.conv1) to the input data x.\n",
    "# F.relu(): Applies the Rectified Linear Unit (ReLU) activation function, which introduces non-linearity to the output of the convolutional layer.\n",
    "# self.pool(): Applies a max-pooling operation to the output of the ReLU activation, downsampling the feature maps and reducing their spatial dimensions.\n",
    "# The comment # -> n, 6, 14, 14 indicates the expected output shape of this step:\n",
    "# n: Batch size.\n",
    "# 6: Number of output channels from the first convolutional layer.\n",
    "# 14, 14: Spatial dimensions of the feature maps after convolution and pooling.\n",
    "# x = self.pool(F.relu(self.conv2(x)))\n",
    "\n",
    "# Similar to the first step, this applies the second convolutional layer (self.conv2), ReLU activation, and max-pooling.\n",
    "# The comment # -> n, 16, 5, 5 indicates the expected output shape after these operations.\n",
    "# x = x.view(-1, 16 * 5 * 5)\n",
    "\n",
    "# This line reshapes the output tensor into a 1D vector.\n",
    "# -1: This tells PyTorch to automatically infer the size of the first dimension (batch size) based on the other dimensions.\n",
    "# This step is necessary to prepare the data for the subsequent fully connected layers, which expect a 1D input.\n",
    "# x = F.relu(self.fc1(x))\n",
    "\n",
    "# This applies the first fully connected layer (self.fc1) to the reshaped input.\n",
    "# F.relu() introduces non-linearity to the output of the fully connected layer.\n",
    "# x = F.relu(self.fc2(x))\n",
    "\n",
    "# This applies the second fully connected layer (self.fc2) and applies ReLU activation.\n",
    "# x = self.fc3(x)\n",
    "\n",
    "# This applies the final fully connected layer (self.fc3), which typically produces the final output of the network. In this case, it likely produces the logits for a classification task.\n",
    "# return x\n",
    "\n",
    "# The output of the final layer (x) is returned by the forward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line defines the loss function, also known as the criterion, as the Cross-Entropy Loss function. This is a common \n",
    "# loss function used for classification problems, where the goal is to predict one of multiple classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code defines the loss function and optimizer for training a neural network in PyTorch:\n",
    "# Loss Function (Criterion)\n",
    "# Python\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# This line defines the loss function, also known as the criterion, as the Cross-Entropy Loss function. This is a common loss function used for classification problems, where the goal is to predict one of multiple classes.\n",
    "# Optimizer\n",
    "# Python\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# This line defines the optimizer as Stochastic Gradient Descent (SGD) with a learning rate of learning_rate. The optimizer is responsible for updating the model's parameters to minimize the loss.\n",
    "# Parameters:\n",
    "# model.parameters(): This specifies the model's parameters that will be updated by the optimizer.\n",
    "# lr=learning_rate: This specifies the learning rate, which controls how quickly the optimizer updates the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass: The input data is passed through the model to produce output.\n",
    "# Loss calculation: The loss is calculated by comparing the model's output to the true labels using the Cross-Entropy Loss function.\n",
    "# Backward pass: The gradients of the loss with respect to the model's parameters are computed using backpropagation.\n",
    "# Optimization: The optimizer updates the model's parameters based on the gradients and the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [2000/12500], Loss: 2.3404\n",
      "Epoch [1/5], Step [4000/12500], Loss: 2.2839\n",
      "Epoch [1/5], Step [6000/12500], Loss: 2.2946\n",
      "Epoch [1/5], Step [8000/12500], Loss: 2.2921\n",
      "Epoch [1/5], Step [10000/12500], Loss: 2.2197\n",
      "Epoch [1/5], Step [12000/12500], Loss: 1.8895\n",
      "Epoch [2/5], Step [2000/12500], Loss: 1.8026\n",
      "Epoch [2/5], Step [4000/12500], Loss: 2.1959\n",
      "Epoch [2/5], Step [6000/12500], Loss: 2.3158\n",
      "Epoch [2/5], Step [8000/12500], Loss: 2.1100\n",
      "Epoch [2/5], Step [10000/12500], Loss: 1.6210\n",
      "Epoch [2/5], Step [12000/12500], Loss: 1.9028\n",
      "Epoch [3/5], Step [2000/12500], Loss: 1.2923\n",
      "Epoch [3/5], Step [4000/12500], Loss: 1.3227\n",
      "Epoch [3/5], Step [6000/12500], Loss: 1.6681\n",
      "Epoch [3/5], Step [8000/12500], Loss: 2.4345\n",
      "Epoch [3/5], Step [10000/12500], Loss: 1.6244\n",
      "Epoch [3/5], Step [12000/12500], Loss: 1.8034\n",
      "Epoch [4/5], Step [2000/12500], Loss: 1.8080\n",
      "Epoch [4/5], Step [4000/12500], Loss: 1.9101\n",
      "Epoch [4/5], Step [6000/12500], Loss: 1.2704\n",
      "Epoch [4/5], Step [8000/12500], Loss: 2.0343\n",
      "Epoch [4/5], Step [10000/12500], Loss: 1.2457\n",
      "Epoch [4/5], Step [12000/12500], Loss: 1.9224\n",
      "Epoch [5/5], Step [2000/12500], Loss: 1.0802\n",
      "Epoch [5/5], Step [4000/12500], Loss: 0.6676\n",
      "Epoch [5/5], Step [6000/12500], Loss: 1.1265\n",
      "Epoch [5/5], Step [8000/12500], Loss: 0.8901\n",
      "Epoch [5/5], Step [10000/12500], Loss: 1.8739\n",
      "Epoch [5/5], Step [12000/12500], Loss: 1.2383\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs): # number of ite\n",
    "    for i, (images, labels) in enumerate(train_loader): # step of optimization\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images) # imput images batch of 4 images\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # optimizer.zero_grad(): Zeroes the gradients of the optimizer.\n",
    "        # loss.backward(): Computes the gradients of the loss with respect to the model's parameters using backpropagation.\n",
    "        # optimizer.step(): Updates the model's parameters based on the gradients and the optimizer's hyperparameters.\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After completing all batches in the training data loader, the outer loop iterates to the next epoch.\n",
    "#  This process repeats until the specified number of epochs is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# The model.state_dict() method returns a dictionary containing the model's learnable parameters, such as weights and \n",
    "# biases. This dictionary is then saved to the file using torch.save()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3333, -0.3984,  0.5888,  0.9898, -0.0356, -0.3488,  0.6005, -1.0401,\n",
       "         -0.0796, -1.0242],\n",
       "        [-0.7543, -0.8260, -1.4718,  1.2833,  0.6378, -1.2884, -0.7987,  0.3762,\n",
       "          0.1999, -0.1315],\n",
       "        [-0.0375,  0.0763,  0.2462, -0.8445,  0.6383,  0.1953, -0.3823, -0.5321,\n",
       "         -3.0301,  0.7948],\n",
       "        [-0.9970,  0.9803,  0.3229,  0.2767, -0.6912,  0.4869, -0.5164, -0.0518,\n",
       "         -2.7684,  1.1579]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 50.14 %\n",
      "Accuracy of plane: 50.2 %\n",
      "Accuracy of car: 67.6 %\n",
      "Accuracy of bird: 41.6 %\n",
      "Accuracy of cat: 21.9 %\n",
      "Accuracy of deer: 35.1 %\n",
      "Accuracy of dog: 47.3 %\n",
      "Accuracy of frog: 54.9 %\n",
      "Accuracy of horse: 63.9 %\n",
      "Accuracy of ship: 67.3 %\n",
      "Accuracy of truck: 51.6 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]   # [0,0,0,0,0,0,0,0,0,0,]\n",
    "    n_class_samples = [0 for i in range(10)]    # [0,0,0,0,0,0,0,0,0,0,]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images) #   outputs class [probalit value for 10 classes for 4 images] as no of batch size 4\n",
    "        # [[-0.3333, -0.3984,  0.5888,  0.9898, -0.0356, -0.3488,  0.6005, -1.0401,\n",
    "        #  -0.0796, -1.0242],\n",
    "        # [-0.7543, -0.8260, -1.4718,  1.2833,  0.6378, -1.2884, -0.7987,  0.3762,\n",
    "        #   0.1999, -0.1315],\n",
    "        # [-0.0375,  0.0763,  0.2462, -0.8445,  0.6383,  0.1953, -0.3823, -0.5321,\n",
    "        #  -3.0301,  0.7948],\n",
    "        # [-0.9970,  0.9803,  0.3229,  0.2767, -0.6912,  0.4869, -0.5164, -0.0518,\n",
    "        #  -2.7684,  1.1579]])\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)  # Finds the [maximum probablity value along the dimension 1 (columns) for each sample in the batch.]\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1 # [4,7,2,0,5,4,7,2,6,2]\n",
    "            n_class_samples[label] += 1     # [12,34,56,32,56,32,67,23,45,23]\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, predicted = torch.max(outputs, 1): This line extracts the predicted class labels from the model's output.\n",
    "# torch.max(outputs, 1): Finds the maximum value along the dimension 1 (columns) for each sample in the batch.\n",
    "# _: Discards the maximum values (logits) and keeps only the indices of the maximum values (predicted class labels) in the predicted variable.\n",
    "# n_samples += labels.size(0): Accumulates the total number of samples in the current batch.\n",
    "# n_correct += (predicted == labels).sum().item(): This line calculates the number of correct predictions in the current batch:\n",
    "# predicted == labels: Creates a tensor where each element is True if the corresponding prediction matches the label, False otherwise.\n",
    "# .sum(): Sums the True elements to get the total number of correct predictions in the batch.\n",
    "# .item(): Converts the tensor containing the number of correct predictions to a Python integer.\n",
    "# 6. Class-wise Accuracy:\n",
    "\n",
    "# for i in range(batch_size): This loop iterates over each sample in the current batch.\n",
    "# label = labels[i]: Gets the ground truth label for the current sample.\n",
    "# pred = predicted[i]: Gets the predicted label for the current sample.\n",
    "# if (label == pred): Checks if the prediction is correct.\n",
    "# n_class_correct[label] += 1: If correct, increments the count of correct predictions for the corresponding class in n_class_correct.\n",
    "# n_class_samples[label] += 1: Increments the total number of samples for the corresponding class in n_class_samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
